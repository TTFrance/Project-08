{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USED OFTEN\n",
    "\n",
    "__SSH to EC2__\n",
    "- gitbash terminal\n",
    "- > ssh OCR-DS-EC2\n",
    "\n",
    "__Launch Juypter on EC2__\n",
    "- open gitbash\n",
    "- > ssh OCR-DS-EC2\n",
    "- > cd ec2-files\n",
    "- > jupyter notebook\n",
    "\n",
    "__Open Local SSH Tunnel to Juypter Remote__\n",
    "- open a new gitbash instance\n",
    "- > ssh OCR-DS-EC2 -L 8888:localhost:8888 -N\n",
    "    ssh OCR-DS-EC2 -L 4040:localhost:4040 -N\n",
    "\n",
    "__Connect locally to remote running Jupyter Instance__\n",
    "- in browser navigate to http://localhost:8888/tree\n",
    "\n",
    "__Open Local SSH Tunnel to Spark Remote__\n",
    "- > ssh OCR-DS-EC2 -L 4040:localhost:4040 -N\n",
    "\n",
    "__Connect locally to remote running Spark Instance__\n",
    "- in browser navigate to http://localhost:4040\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created AWS account\n",
    "configured budget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create PEM key\n",
    "- key name: oc_ds_p8-asp\n",
    "- PEM key is oc_ds_p8-asp.pem \n",
    "- stored in C:\\Users\\adam_\\Desktop\\OC\\Project 08 Supporting Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create EC2 instance\n",
    "- name: oc-ds-p8-asp-ec2\n",
    "- type: t2.micro\n",
    "- memory: 16gb\n",
    "- using key-pair PEM from step above\n",
    "- left network setting default (port 22 only)\n",
    "- public ip: ec2-35-180-139-148.eu-west-3.compute.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Gitbash\n",
    "- created C:\\Users\\adam_\\.ssh (local)\n",
    "- copied .pem file to this location\n",
    "- created C:\\Users\\adam_\\.ssh\\config with contents\n",
    "    - Host OCR-DS-EC2\n",
    "        - Hostname     ec2-35-180-139-148.eu-west-3.compute.amazonaws.com\n",
    "        -  User         ubuntu\n",
    "        -  IdentityFile ~/.ssh/oc_ds_p8-asp.pem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect SSH to EC2\n",
    "\n",
    "- gitbash terminal\n",
    "- > ssh OCR-DS-EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update EC2 Instance, Install Python, P8 Env\n",
    "- connect to EC2\n",
    "    - gitbash terminal\n",
    "    - > ssh OCR-DS-EC2\n",
    "- update EC2 instance\n",
    "    - > sudo apt update\n",
    "    - > sudo apt upgrade -y\n",
    "- install python\n",
    "    - > sudo apt install -y python3-pip\n",
    "- check python version\n",
    "    - > python --version\n",
    "    - if not python 3 THEN \n",
    "        - > sudo update-alternatives --install /usr/bin/python python /usr/bin/python3 10\n",
    "        - > python --version\n",
    "- > echo 'export PATH=$PATH:$HOME/.local/bin' >> ~/.bashrc\n",
    "- Re-démarrer votre connection SSH pour prendre en compte cet ajout\n",
    "- Installer les packages python pour Jupyter et la data-science\n",
    "    - > pip install -U pip\n",
    "    - > pip install jupyter\n",
    "    - > pip install pandas numpy matplotlib seaborn scikit-learn tensorflow --no-cache-dir\n",
    "- Il faut aussi configurer des extensions pour jupyter notebook\n",
    "    - > jupyter nbextension install --py widgetsnbextension --user\n",
    "    - > jupyter nbextension enable widgetsnbextension --user --py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create folder for notebook(s)\n",
    "- connect SSH to EC2\n",
    "- > mkdir ec2-files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transferring files from local to ec2\n",
    "- open gitbash (no need to connect to EC2)\n",
    "- > cd 'C:/Users/adam_/Desktop/OC/project 08' (source folder)\n",
    "- > scp ./oc-p8-modelling.ipynb OCR-DS-EC2:ec2-files/oc-p8-modelling.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch Juypter on EC2\n",
    "- open gitbash\n",
    "- > ssh OCR-DS-EC2\n",
    "- > cd ec2-files\n",
    "- > jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open SSH Tunnel EC2 > Local\n",
    "- open a new gitbash instance\n",
    "- > ssh OCR-DS-EC2 -L 8888:localhost:8888 -N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect locally to remote running Jupyter Instance \n",
    "- in browser navigate to http://localhost:8888/tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy files to EC2 (filezilla SFTP)\n",
    "- Open filezilla\n",
    "- connect to OC EC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create user for EC2 to S3\n",
    "- https://us-east-1.console.aws.amazon.com/iamv2/home#/users\n",
    "- Add User\n",
    "- name: ocr-p8-robot\n",
    "- AWS Access Type: Access Key\n",
    "- Attach Existing Policies Directly: AmazonS3FullAccess\n",
    "- No tags\n",
    "- Save key-pair (new_user_credentials oc-p8_robot.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation sur l'EC2\n",
    "\n",
    "- En console, avec awscli (shell)\n",
    "\n",
    "- in EC2 terminal (typically from ssh)\n",
    "    - > pip3 install awscli\n",
    "    - > aws --version\n",
    "\n",
    "- > aws configure\n",
    "    - AWS Access Key ID [None]: AKIA6J42R23PVNBUKAXF (new_user_credentials ocr-p8-robot.csv)\n",
    "    - AWS Secret Access Key [None]: dyBX**************** (new_user_credentials ocr-p8-robot.csv)\n",
    "    - Default region name [None]: eu-west-3 (S3 buckets location)\n",
    "    - Default output format [None]: json\n",
    "\n",
    "- > ls ~/.aws/\n",
    "    - config  credentials\n",
    "\n",
    "# ERROR\n",
    "- > aws s3 ls\n",
    "- Could not connect to the endpoint URL: \"https://s3.eu-west-3c.amazonaws.com/\"\n",
    "- FIXED: Default region name [None]: SHOULD BE 'eu-west-3', not 'eu-west-3c'\n",
    "    - reconfigured the settings by running aws configure again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Boto3\n",
    "- connect to EC2\n",
    "- pip3 install awscli boto3[crt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Pyspark on EC2\n",
    "- connect SSH to EC2\n",
    "- packages debian for JAVA (DONE)\n",
    "    - > sudo apt-get install default.jre scala\n",
    "- packages python for pyspark (it embeds hadoop jars) (DONE)\n",
    "    - > pip3 install pyspark py4j findspark\n",
    "- Vérifier la version hadoop embarquée avec pyspark:\n",
    "    - > ls ~/.local/lib/python*/site-packages/pyspark/jars/hadoop-client-*\n",
    "    - 3.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Apache Hadoop AWS Services Support\n",
    "- in EC2 SSH Terminal\n",
    "\n",
    "```\n",
    "JARS=/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/jars\n",
    "HADOOP_V=3.3.2\n",
    "AWS_V=1.12.286\n",
    "REPO=https://repo1.maven.org/maven2\n",
    "wget ${REPO}/org/apache/hadoop/hadoop-aws/${HADOOP_V}/hadoop-aws-${HADOOP_V}.jar\n",
    "wget ${REPO}/com/amazonaws/aws-java-sdk-bundle/${AWS_V}/aws-java-sdk-bundle-${AWS_V}.jar\n",
    "mv *.jar ${JARS}/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check spark with jupyter notebook 'test_02_spark_pi.ipynb'\n",
    "- Notebook runs successfuly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La Spark UI (NOT WORKING)\n",
    "\n",
    "__Open Local SSH Tunnel to Spark Remote__\n",
    "- > ssh OCR-DS-EC2 -L 4040:localhost:4040 -N\n",
    "\n",
    "__Connect locally to remote running Spark Instance__\n",
    "- in browser navigate to http://localhost:4040\n",
    "\n",
    "__!! ERROR !!__\n",
    "- channel 2: open failed: connect failed: Connection refused\n",
    "- in https://github.com/chaug/OCR-DS-P8-docs/blob/main/SETUP-pyspark-french.md\n",
    "\n",
    "__ABOVE ERROR FIXED__\n",
    "- the error was because the last cell of the above notebook stop the server (sc.stop())\n",
    "- commenting this out and rerunning the notebook allows the subsequent connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'test_03_spark_pi.ipynb'\n",
    "__!! ERROR !!__\n",
    "- Runs but breaks at the cell df = src\n",
    "- seems to hang\n",
    "\n",
    "__ABOVE ERROR FIXED__\n",
    "- fixed by stopping other notebooks which may have run previously, are still running, and take up huge amounts of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __TODO__\n",
    "\n",
    "### User defined functions (UDFs)\n",
    "- really get a handle on user defined functions\n",
    "\n",
    "### EC2 machine type\n",
    "- at least EC2 t2.medium for images\n",
    "\n",
    "PCA with scalar (in sparkml deja"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b6f224b3d7daa80c0152910d5f33be0adb657cce3f5b079f96ab8316ce7174b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
